{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "755fa9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"session_name\": \"test\",\n",
      "    \"session_description\": \"test\",\n",
      "    \"design_state_data\": {\n",
      "\n",
      "      \"session_info\" : {\n",
      "        \"project_id\": \"1\",\n",
      "        \"experiment_id\": \"kkkk-11\",\n",
      "        \"dataset\":\"iris_modified.csv\",\n",
      "        \"session_name\": \"test\",\n",
      "        \"session_description\": \"test\"\n",
      "        },\n",
      "\n",
      "      \"target\": {\n",
      "        \"prediction_type\": \"Regression\",\n",
      "        \"target\": \"petal_width\",\n",
      "        \"type\":\"regression\",\n",
      "        \"partitioning\": true\n",
      "      },\n",
      "      \"train\": {\n",
      "        \"policy\": \"Split the dataset\",\n",
      "        \"time_variable\": \"sepal_length\",\n",
      "        \"sampling_method\": \"No sampling(whole data)\",\n",
      "        \"split\": \"Randomly\",\n",
      "        \"k_fold\": false,\n",
      "        \"train_ratio\": 0,\n",
      "        \"random_seed\": 0\n",
      "      },\n",
      "      \"metrics\": {\n",
      "        \"optomize_model_hyperparameters_for\": \"AUC\",\n",
      "        \"optimize_threshold_for\": \"F1 Score\",\n",
      "        \"compute_lift_at\": 0,\n",
      "        \"cost_matrix_gain_for_true_prediction_true_result\": 1,\n",
      "        \"cost_matrix_gain_for_true_prediction_false_result\": 0,\n",
      "        \"cost_matrix_gain_for_false_prediction_true_result\": 0,\n",
      "        \"cost_matrix_gain_for_false_prediction_false_result\": 0\n",
      "      },\n",
      "      \"feature_handling\": {\n",
      "        \"sepal_length\": {\n",
      "          \"feature_name\": \"sepal_length\",\n",
      "          \"is_selected\": true,\n",
      "          \"feature_variable_type\": \"numerical\",\n",
      "          \"feature_details\": {\n",
      "            \"numerical_handling\": \"Keep as regular numerical feature\",\n",
      "            \"rescaling\": \"No rescaling\",\n",
      "            \"make_derived_feats\": false,\n",
      "            \"missing_values\": \"Impute\",\n",
      "            \"impute_with\": \"Average of values\",\n",
      "            \"impute_value\": 0\n",
      "          }\n",
      "        },\n",
      "        \"sepal_width\": {\n",
      "          \"feature_name\": \"sepal_width\",\n",
      "          \"is_selected\": true,\n",
      "          \"feature_variable_type\": \"numerical\",\n",
      "          \"feature_details\": {\n",
      "            \"numerical_handling\": \"Keep as regular numerical feature\",\n",
      "            \"rescaling\": \"No rescaling\",\n",
      "            \"make_derived_feats\": false,\n",
      "            \"missing_values\": \"Impute\",\n",
      "            \"impute_with\": \"custom\",\n",
      "            \"impute_value\": -1\n",
      "          }\n",
      "        },\n",
      "        \"petal_length\": {\n",
      "          \"feature_name\": \"petal_length\",\n",
      "          \"is_selected\": true,\n",
      "          \"feature_variable_type\": \"numerical\",\n",
      "          \"feature_details\": {\n",
      "            \"numerical_handling\": \"Keep as regular numerical feature\",\n",
      "            \"rescaling\": \"No rescaling\",\n",
      "            \"make_derived_feats\": false,\n",
      "            \"missing_values\": \"Impute\",\n",
      "            \"impute_with\": \"Average of values\",\n",
      "            \"impute_value\": 0\n",
      "          }\n",
      "        },\n",
      "        \"petal_width\": {\n",
      "          \"feature_name\": \"petal_width\",\n",
      "          \"is_selected\": true,\n",
      "          \"feature_variable_type\": \"numerical\",\n",
      "          \"feature_details\": {\n",
      "            \"numerical_handling\": \"Keep as regular numerical feature\",\n",
      "            \"rescaling\": \"No rescaling\",\n",
      "            \"make_derived_feats\": false,\n",
      "            \"missing_values\": \"Impute\",\n",
      "            \"impute_with\": \"custom\",\n",
      "            \"impute_value\": -2\n",
      "          }\n",
      "        },\n",
      "        \"species\": {\n",
      "          \"feature_name\": \"species\",\n",
      "          \"is_selected\": true,\n",
      "          \"feature_variable_type\": \"text\",\n",
      "          \"feature_details\": {\n",
      "            \"text_handling\": \"Tokenize and hash\",\n",
      "            \"hash_columns\": 0\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"feature_generation\": {\n",
      "        \"linear_interactions\": [[\"petal_length\", \"sepal_width\"]],\n",
      "        \"linear_scalar_type\": \"robust\",\n",
      "        \"polynomial_interactions\": [\n",
      "          \"petal_length/sepal_width\",\n",
      "          \"petal_width/species\"\n",
      "        ],\n",
      "        \"explicit_pairwise_interactions\": [\n",
      "          \"sepal_width/sepal_length\",\n",
      "          \"petal_width/sepal_length\"\n",
      "        ]\n",
      "      },\n",
      "      \"feature_reduction\": {\n",
      "        \"feature_reduction_method\": \"Tree-based\",\n",
      "        \"num_of_features_to_keep\": \"4\",\n",
      "        \"num_of_trees\": \"5\",\n",
      "        \"depth_of_trees\": \"6\"\n",
      "      },\n",
      "      \"hyperparameters\": {\n",
      "        \"stratergy\": \"Grid Search\",\n",
      "        \"shuffle_grid\": true,\n",
      "        \"random_state\": 1,\n",
      "        \"max_iterations\": 2,\n",
      "        \"max_search_time\": 3,\n",
      "        \"parallelism\": 5,\n",
      "        \"cross_validation_stratergy\": \"Time-based K-fold(with overlap)\",\n",
      "        \"num_of_folds\": 6,\n",
      "        \"split_ratio\": 0,\n",
      "        \"stratified\": true\n",
      "      },\n",
      "      \"weighting_stratergy\": {\n",
      "        \"weighting_stratergy_method\": \"Sample weights\",\n",
      "        \"weighting_stratergy_weight_variable\": \"petal_length\"\n",
      "      },\n",
      "      \"probability_calibration\": {\n",
      "        \"probability_calibration_method\": \"Sigmoid - Platt Scaling\"\n",
      "      },\n",
      "      \"algorithms\": {\n",
      "        \"RandomForestClassifier\": {\n",
      "          \"model_name\": \"Random Forest Classifier\",\n",
      "          \"is_selected\": false,\n",
      "          \"min_trees\": 10,\n",
      "          \"max_trees\": 30,\n",
      "          \"feature_sampling_statergy\": \"Default\",\n",
      "          \"min_depth\": 20,\n",
      "          \"max_depth\": 30,\n",
      "          \"min_samples_per_leaf_min_value\": 5,\n",
      "          \"min_samples_per_leaf_max_value\": 50,\n",
      "          \"parallelism\": 0\n",
      "        },\n",
      "        \"RandomForestRegressor\": {\n",
      "          \"model_name\": \"Random Forest Regressor\",\n",
      "          \"is_selected\": true,\n",
      "          \"min_trees\": 10,\n",
      "          \"max_trees\": 20,\n",
      "          \"feature_sampling_statergy\": \"Default\",\n",
      "          \"min_depth\": 20,\n",
      "          \"max_depth\": 25,\n",
      "          \"min_samples_per_leaf_min_value\": 5,\n",
      "          \"min_samples_per_leaf_max_value\": 10,\n",
      "          \"parallelism\": 0\n",
      "        },\n",
      "        \"GBTClassifier\": {\n",
      "          \"model_name\": \"Gradient Boosted Trees\",\n",
      "          \"is_selected\": false,\n",
      "          \"num_of_BoostingStages\": [67, 89],\n",
      "          \"feature_sampling_statergy\": \"Fixed number\",\n",
      "          \"learningRate\": [],\n",
      "          \"use_deviance\": true,\n",
      "          \"use_exponential\": false,\n",
      "          \"fixed_number\": 22,\n",
      "          \"min_subsample\": 1,\n",
      "          \"max_subsample\": 2,\n",
      "          \"min_stepsize\":0.1,\n",
      "          \"max_stepsize\":0.5, \n",
      "          \"min_iter\":20,\n",
      "          \"max_iter\":40,\n",
      "          \"min_depth\":5,\n",
      "          \"max_depth\":7\n",
      "\n",
      "        },\n",
      "        \"GBTRegressor\": {\n",
      "          \"model_name\": \"Gradient Boosted Trees\",\n",
      "          \"is_selected\": false,\n",
      "          \"num_of_BoostingStages\": [67, 89],\n",
      "          \"feature_sampling_statergy\": \"Fixed number\",\n",
      "          \"use_deviance\": true,\n",
      "          \"use_exponential\": false,\n",
      "          \"fixed_number\": 22,\n",
      "          \"min_subsample\": 1,\n",
      "          \"max_subsample\": 2,\n",
      "          \"min_stepsize\":0.1,\n",
      "          \"max_stepsize\":0.5, \n",
      "          \"min_iter\":20,\n",
      "          \"max_iter\":40,\n",
      "          \"min_depth\":5,\n",
      "          \"max_depth\":7\n",
      "        },\n",
      "        \"LinearRegression\": {\n",
      "          \"model_name\": \"LinearRegression\",\n",
      "          \"is_selected\": false,\n",
      "          \"parallelism\": 2,\n",
      "          \"min_iter\":30,\n",
      "          \"max_iter\":50,\n",
      "          \"min_regparam\":0.5,\n",
      "          \"max_regparam\":0.8,\n",
      "          \"min_elasticnet\":0.5,\n",
      "          \"max_elasticnet\":0.8\n",
      "        },\n",
      "        \"LogisticRegression\": {\n",
      "          \"model_name\": \"LogisticRegression\",\n",
      "          \"is_selected\": false,\n",
      "          \"parallelism\": 2,\n",
      "          \"min_iter\":30,\n",
      "          \"max_iter\":50,\n",
      "          \"min_regparam\":0.5,\n",
      "          \"max_regparam\":0.8,\n",
      "          \"min_elasticnet\":0.5,\n",
      "          \"max_elasticnet\":0.8\n",
      "        },\n",
      "        \"RidgeRegression\": {\n",
      "          \"model_name\": \"RidgeRegression\",\n",
      "          \"is_selected\": false,\n",
      "          \"regularization_term\": \"Specify values to test\",\n",
      "          \"min_iter\":30,\n",
      "          \"max_iter\":50,\n",
      "          \"min_regparam\":0.5,\n",
      "          \"max_regparam\":0.8\n",
      "        },\n",
      "        \"LassoRegression\": {\n",
      "          \"model_name\": \"Lasso Regression\",\n",
      "          \"is_selected\": false,\n",
      "          \"regularization_term\": \"Specify values to test\",\n",
      "          \"min_iter\":30,\n",
      "          \"max_iter\":50,\n",
      "          \"min_regparam\":0.5,\n",
      "          \"max_regparam\":0.8\n",
      "        },\n",
      "        \"ElasticNetRegression\": {\n",
      "          \"model_name\": \"Lasso Regression\",\n",
      "          \"is_selected\": false,\n",
      "          \"regularization_term\": \"Specify values to test\",\n",
      "          \"min_iter\":30,\n",
      "          \"max_iter\":50,\n",
      "          \"min_regparam\":0.5,\n",
      "          \"max_regparam\":0.8,\n",
      "          \"min_elasticnet\":0.5,\n",
      "          \"max_elasticnet\":0.8\n",
      "        },\n",
      "        \"xg_boost\": {\n",
      "          \"model_name\": \"XG Boost\",\n",
      "          \"is_selected\": false,\n",
      "          \"use_gradient_boosted_tree\": true,\n",
      "          \"dart\": true,\n",
      "          \"tree_method\": \"\",\n",
      "          \"random_state\": 0,\n",
      "          \"max_num_of_trees\": 0,\n",
      "          \"early_stopping\": true,\n",
      "          \"early_stopping_rounds\": 2,\n",
      "          \"max_depth_of_tree\": [56, 89], \n",
      "          \"learningRate\": [89, 76],\n",
      "          \"l1_regularization\": [77],\n",
      "          \"l2_regularization\": [78],\n",
      "          \"gamma\": [68],\n",
      "          \"min_child_weight\": [67],\n",
      "          \"sub_sample\": [67],\n",
      "          \"col_sample_by_tree\": [67],\n",
      "          \"replace_missing_values\": false,\n",
      "          \"parallelism\": 0\n",
      "        },\n",
      "        \"DecisionTreeRegressor\": {\n",
      "          \"model_name\": \"Decision Tree\",\n",
      "          \"is_selected\": false,\n",
      "          \"min_depth\":4,\n",
      "          \"max_depth\": 7,\n",
      "          \"use_gini\": false,\n",
      "          \"use_entropy\": true,\n",
      "          \"min_samples_per_leaf\": [12, 6],\n",
      "          \"use_best\": true,\n",
      "          \"use_random\": true\n",
      "        },\n",
      "        \"DecisionTreeClassifier\": {\n",
      "          \"model_name\": \"Decision Tree\",\n",
      "          \"is_selected\": false,\n",
      "          \"min_depth\":4,\n",
      "          \"max_depth\": 7,\n",
      "          \"use_gini\": false,\n",
      "          \"use_entropy\": true,\n",
      "          \"min_samples_per_leaf\": [12, 6],\n",
      "          \"use_best\": true,\n",
      "          \"use_random\": true\n",
      "        },\n",
      "        \"SVM\": {\n",
      "          \"model_name\": \"Support Vector Machine\",\n",
      "          \"is_selected\": false,\n",
      "          \"linear_kernel\": true,\n",
      "          \"rep_kernel\": true,\n",
      "          \"polynomial_kernel\": true,\n",
      "          \"sigmoid_kernel\": true,\n",
      "          \"c_value\": [566, 79],\n",
      "          \"auto\": true,\n",
      "          \"scale\": true,\n",
      "          \"custom_gamma_values\": true,\n",
      "          \"tolerance\": 7,\n",
      "          \"max_iterations\": 7\n",
      "        },\n",
      "        \"SGD\": {\n",
      "          \"model_name\": \"Stochastic Gradient Descent\",\n",
      "          \"is_selected\": false,\n",
      "          \"use_logistics\": true,\n",
      "          \"use_modified_hubber_loss\": false,\n",
      "          \"max_iterations\": false,\n",
      "          \"tolerance\": 56,\n",
      "          \"use_l1_regularization\": \"on\",\n",
      "          \"use_l2_regularization\": \"on\",\n",
      "          \"use_elastic_net_regularization\": true,\n",
      "          \"alpha_value\": [79, 56],\n",
      "          \"parallelism\": 1\n",
      "        },\n",
      "        \"KNN\": {\n",
      "          \"model_name\": \"KNN\",\n",
      "          \"is_selected\": false,\n",
      "          \"k_value\": [78],\n",
      "          \"distance_weighting\": true,\n",
      "          \"neighbour_finding_algorithm\": \"Automatic\",\n",
      "          \"random_state\": 0,\n",
      "          \"p_value\": 0\n",
      "        },\n",
      "        \"extra_random_trees\": {\n",
      "          \"model_name\": \"Extra Random Trees\",\n",
      "          \"is_selected\": false,\n",
      "          \"num_of_trees\": [45, 489],\n",
      "          \"feature_sampling_statergy\": \"Square root and Logarithm\",\n",
      "          \"max_depth\": [12, 45],\n",
      "          \"min_samples_per_leaf\": [78, 56],\n",
      "          \"parallelism\": 3\n",
      "        },\n",
      "        \"neural_network\": {\n",
      "          \"model_name\": \"Neural Network\",\n",
      "          \"is_selected\": false,\n",
      "          \"hidden_layer_sizes\": [67, 89],\n",
      "          \"activation\": \"\",\n",
      "          \"alpha_value\": 0,\n",
      "          \"max_iterations\": 0,\n",
      "          \"convergence_tolerance\": 0,\n",
      "          \"early_stopping\": true,\n",
      "          \"solver\": \"ADAM\",\n",
      "          \"shuffle_data\": true,\n",
      "          \"initial_learning_rate\": 0,\n",
      "          \"automatic_batching\": true,\n",
      "          \"beta_1\": 0,\n",
      "          \"beta_2\": 0,\n",
      "          \"epsilon\": 0,\n",
      "          \"power_t\": 0,\n",
      "          \"momentum\": 0,\n",
      "          \"use_nesterov_momentum\": false\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from striprtf.striprtf import rtf_to_text\n",
    "\n",
    "with open('algoparams_from_ui.json.rtf') as json_file:\n",
    "    content = json_file.read()\n",
    "    file = rtf_to_text(content)\n",
    "print(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eec0db52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "394c815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read target and models\n",
    "import pandas as pd\n",
    "\n",
    "target_column = data['design_state_data']['target']\n",
    "algorithms = data['design_state_data']['algorithms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0e6ecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a75b53ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b139629",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Convert tokens to lowercase for consistent hashing\n",
    "    tokens_lower = [token.lower() for token in tokens]\n",
    "    return tokens_lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a8a0a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_hash(df, hash_columns=0):\n",
    "    # Convert the DataFrame to a dictionary of lists\n",
    "    data_dict = df.to_dict(orient='list')\n",
    "\n",
    "    # Initialize a defaultdict to store hash values for each column\n",
    "    hash_values = defaultdict(list)\n",
    "\n",
    "    # Iterate through the columns and tokenize + hash text columns\n",
    "    for col, values in data_dict.items():\n",
    "        if col in df.select_dtypes(include=['object']):\n",
    "            for value in values:\n",
    "                tokens = tokenize(value)\n",
    "                \n",
    "                # Create a hashlib object\n",
    "                hash_obj = hashlib.sha256()\n",
    "                hash_obj.update(''.join(tokens).encode('utf-8'))\n",
    "                hash_result = hash_obj.hexdigest()\n",
    "                hash_values[col].append(hash_result)\n",
    "        else:\n",
    "            # For non-text columns, add original values\n",
    "            hash_values[col] = values\n",
    "\n",
    "    # Convert the dictionary of hash values back to a DataFrame\n",
    "    hashed_df = pd.DataFrame(hash_values)\n",
    "\n",
    "    # If hash_columns is specified, keep only the specified number of hash columns\n",
    "    if hash_columns > 0:\n",
    "        hash_columns_to_keep = list(hashed_df.columns)[:hash_columns]\n",
    "        hashed_df = hashed_df[hash_columns_to_keep]\n",
    "\n",
    "    return hashed_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71756e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n",
      "sepal_length\n",
      "sepal_width\n",
      "petal_length\n",
      "petal_width\n",
      "species\n"
     ]
    }
   ],
   "source": [
    "if 'feature_handling' in data['design_state_data']:\n",
    "    print(\"Yes\")\n",
    "    feature_handling = data['design_state_data']['feature_handling']\n",
    "    \n",
    "    for k, v in feature_handling.items():\n",
    "        print(k)\n",
    "        \n",
    "        #feature_name_specific = feature_handling['sepal_length']\n",
    "    \n",
    "        feature_name = v['feature_name']\n",
    "        feature_details = v['feature_details']\n",
    "        \n",
    "        if 'missing_values' in feature_details:\n",
    "            impute_strategy = feature_details['impute_with']\n",
    "            impute_value = feature_details['impute_value']\n",
    "    \n",
    "            if impute_strategy == \"Average of values\":\n",
    "                impute_value = dataset[feature_name].mean()\n",
    "                \n",
    "            elif impute_strategy == \"custom\":\n",
    "                impute_value = feature_details['impute_value']\n",
    "        \n",
    "            dataset[feature_name].fillna(impute_value, inplace =True)\n",
    "            \n",
    "        if 'text_handling' in feature_details:\n",
    "            \n",
    "            df = pd.DataFrame(dataset[feature_name])\n",
    "            hashed_df = dataframe_hash(df, hash_columns=1)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39b4cfbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length    0\n",
       "sepal_width     0\n",
       "petal_length    0\n",
       "petal_width     0\n",
       "species         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b11b251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal_length  sepal_width  petal_length  petal_width\n",
       "count    150.000000   150.000000    150.000000   150.000000\n",
       "mean       5.843333     3.054000      3.758667     1.198667\n",
       "std        0.828066     0.433594      1.764420     0.763161\n",
       "min        4.300000     2.000000      1.000000     0.100000\n",
       "25%        5.100000     2.800000      1.600000     0.300000\n",
       "50%        5.800000     3.000000      4.350000     1.300000\n",
       "75%        6.400000     3.300000      5.100000     1.800000\n",
       "max        7.900000     4.400000      6.900000     2.500000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45294092",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_extraction.text import CountVectorizer, FeatureHasher\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e57a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'feature_reduction' in data['design_state_data']:\n",
    "    target_column = data['design_state_data']['target']['target']\n",
    "    c = data['design_state_data']['feature_reduction']\n",
    "    \n",
    "    if 'No_reduction' in c:\n",
    "        k0 = c['No_reduction']['num_of_features_to_keep']\n",
    "        k_best = SelectKBest(f_regression, k = k0)\n",
    "        selected_features = k_best.fit_transform(dataset.drop(target_column, axis=1), dataset[target_column])\n",
    "        selected_feature_indices = k_best.get_support(indices=True)\n",
    "        selected_feature_names = dataset.drop(target_column, axis=1).columns[selected_feature_indices]\n",
    "        dataset = dataset[selected_feature_names.tolist() + [target_column]]\n",
    "    \n",
    "    elif 'Corr with Target' in c:\n",
    "        k0 = c['Corr with Target']['num_of_features_to_keep']\n",
    "        corr_matrix = dataset.corr()\n",
    "        corr_with_target = corr_matrix[target_column].drop(target_column)\n",
    "        selected_features = corr_with_target[abs(corr_with_target) > k0].index.tolist()\n",
    "        dataset = dataset[selected_features + [target_column]]\n",
    "        \n",
    "    elif 'Tree-based' in c:\n",
    "        depth = c['Tree-based']['depth_of_trees']\n",
    "        num = c['Tree-based']['num_of_trees']\n",
    "        k0 = c['Tree-based']['num_of_features_to_keep']\n",
    "        model = RandomForestRegressor(n_estimators = num, max_depth=depth)\n",
    "        model.fit(dataset.drop(target_column, axis=1), dataset[target_column])\n",
    "        feature_importances = model.feature_importances_\n",
    "        selected_indices = SelectFromModel(model, threshold=k0).fit_transform(dataset.drop(target_column, axis=1))\n",
    "        selected_features = dataset.drop(target_column, axis=1).columns[selected_indices]\n",
    "        dataset = dataset[selected_features.tolist() + [target_column]]\n",
    "    \n",
    "    elif 'Principal Component Analysis':\n",
    "        k0 = c['Principal Component Analysis']['num_of_features_to_keep']\n",
    "        pca = PCA(n_components=k0)\n",
    "        reduced_features = pca.fit_transform(dataset.drop(target_column, axis=1))\n",
    "        reduced_dataset = pd.DataFrame(reduced_features, columns=[f'PC{i+1}' for i in range(k0)])\n",
    "        dataset = pd.concat([reduced_dataset, dataset[target_column]], axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07ade7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns = ['petal_width'],axis = 1)\n",
    "Y = dataset.petal_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9beb9699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5deea73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LogisticRegression\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be45a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'algorithms' in data['design_state_data']:\n",
    "    model_list = data['design_state_data']['algorithms']\n",
    "    \n",
    "    model_results = []\n",
    "    \n",
    "    for algorithm, config in model_list.items():\n",
    "        if config['is_selected']:\n",
    "            model_name = config['model_name']\n",
    "            \n",
    "            if algorithm == 'RandomForestClassifier':\n",
    "                model = RandomForestClassifier(\n",
    "                    n_estimators=config['min_trees'],\n",
    "                    max_depth=config['max_depth'],\n",
    "                    min_samples_split=config['min_samples_per_leaf_min_value'],\n",
    "                    min_samples_leaf=config['min_samples_per_leaf_max_value'],\n",
    "                    n_jobs=config['parallelism']\n",
    "                )\n",
    "                \n",
    "            elif algorithm == 'RandomForestRegressor':\n",
    "                model = RandomForestRegressor(\n",
    "                    n_estimators=config['min_trees'],\n",
    "                    max_depth=config['max_depth'],\n",
    "                    min_samples_split=config['min_samples_per_leaf_min_value'],\n",
    "                    min_samples_leaf=config['min_samples_per_leaf_max_value'],\n",
    "                    n_jobs=config['parallelism']\n",
    "                )\n",
    "                \n",
    "            elif algorithm == 'GBTClassifier':\n",
    "                model = GradientBoostingClassifier(\n",
    "                    n_estimators=config['num_of_BoostingStages'][0],\n",
    "                    learning_rate=config['learningRate'][0],\n",
    "                    subsample=config['min_subsample'],\n",
    "                    max_depth=config['max_depth'],\n",
    "                    random_state=config['random_state'],\n",
    "                    criterion='deviance' if config['use_deviance'] else 'exponential'\n",
    "                )\n",
    "\n",
    "            elif algorithm == 'GBTRegressor':\n",
    "                model = GradientBoostingRegressor(\n",
    "                    n_estimators=config['num_of_BoostingStages'][0],\n",
    "                    learning_rate=config['learningRate'][0],\n",
    "                    subsample=config['min_subsample'],\n",
    "                    max_depth=config['max_depth']\n",
    "                )\n",
    "                \n",
    "            elif algorithm == 'LinearRegression':\n",
    "                model = LinearRegression(\n",
    "                    n_jobs=config['parallelism']\n",
    "                )\n",
    "\n",
    "            elif algorithm == 'LogisticRegression':\n",
    "                model = LogisticRegression(\n",
    "                    n_jobs=config['parallelism'],\n",
    "                    max_iter=config['max_iter'],\n",
    "                    C=config['min_regparam'],\n",
    "                    penalty='l1' if config['use_l1_regularization'] else 'l2',\n",
    "                    solver='saga' if config['use_elastic_net_regularization'] else 'auto'\n",
    "                )\n",
    "\n",
    "            elif algorithm == 'RidgeRegression':\n",
    "                model = Ridge(\n",
    "                    max_iter=config['max_iter'],\n",
    "                    alpha=config['min_regparam'],\n",
    "                    tol=config['max_regparam']\n",
    "                )\n",
    "                \n",
    "            elif algorithm == 'LassoRegression':\n",
    "                model = Lasso(\n",
    "                    max_iter=config['max_iter'],\n",
    "                    alpha=config['min_regparam'],\n",
    "                    tol=config['max_regparam']\n",
    "                )\n",
    "\n",
    "            elif algorithm == 'ElasticNetRegression':\n",
    "                model = ElasticNet(\n",
    "                    max_iter=config['max_iter'],\n",
    "                    alpha=config['min_regparam'],\n",
    "                    l1_ratio=config['min_elasticnet'],\n",
    "                    tol=config['max_regparam']\n",
    "                )\n",
    "            \n",
    "            elif algorithm == 'xg_boost':\n",
    "                model = XGBClassifier(\n",
    "                    n_estimators=config['max_num_of_trees'],\n",
    "                    learning_rate=config['learningRate'][1],\n",
    "                    max_depth=config['max_depth_of_tree'][1],\n",
    "                    subsample=config['sub_sample'][0],\n",
    "                    colsample_bytree=config['col_sample_by_tree'][0],\n",
    "                    random_state=config['random_state'],\n",
    "                    use_label_encoder=False if config['use_gradient_boosted_tree'] else True\n",
    "                )\n",
    "\n",
    "            elif algorithm == 'DecisionTreeClassifier':\n",
    "                model = DecisionTreeClassifier(\n",
    "                    max_depth=config['max_depth'],\n",
    "                    min_samples_split=config['min_samples_per_leaf'][0],\n",
    "                    min_samples_leaf=config['min_samples_per_leaf'][1],\n",
    "                    criterion='gini' if config['use_gini'] else 'entropy',\n",
    "                    splitter='best' if config['use_best'] else 'random',\n",
    "                    random_state=config['use_random']\n",
    "                )\n",
    "\n",
    "            elif algorithm == 'DecisionTreeRegressor':\n",
    "                model = DecisionTreeRegressor(\n",
    "                    max_depth=config['max_depth'],\n",
    "                    min_samples_split=config['min_samples_per_leaf'][0],\n",
    "                    min_samples_leaf=config['min_samples_per_leaf'][1],\n",
    "                    criterion='mse' if config['use_best'] else 'mae',\n",
    "                    splitter='best' if config['use_best'] else 'random',\n",
    "                    random_state=config['use_random']\n",
    "                )\n",
    "\n",
    "            elif algorithm == 'SVM':\n",
    "                model = SVC(\n",
    "                    C=config['c_value'][0],\n",
    "                    kernel='linear' if config['linear_kernel'] else 'rbf',\n",
    "                    degree=3 if config['polynomial_kernel'] else 0,\n",
    "                    gamma='scale' if config['auto'] else 'auto' if config['scale'] else 'scale', # You might need to adjust this based on your requirements\n",
    "                    tol=config['tolerance'],\n",
    "                    max_iter=config['max_iterations']\n",
    "                )\n",
    "\n",
    "            elif algorithm == 'SGD':\n",
    "                model = SGDRegressor(\n",
    "                    loss='log' if config['use_logistics'] else 'squared_loss',\n",
    "                    penalty='elasticnet' if config['use_elastic_net_regularization'] else 'l2',\n",
    "                    alpha=config['alpha_value'][0],\n",
    "                    max_iter=config['max_iterations'],\n",
    "                    tol=config['tolerance'],\n",
    "                    l1_ratio=config['use_l1_regularization'],\n",
    "                    l2_ratio=config['use_l2_regularization'],\n",
    "                    learning_rate='constant',\n",
    "                    eta0=0.01,  # You might need to adjust this based on your requirements\n",
    "                    early_stopping=True if config['use_elastic_net_regularization'] else False\n",
    "                )\n",
    "                \n",
    "            elif algorithm == 'KNN':\n",
    "                model = KNeighborsClassifier(\n",
    "                    n_neighbors=config['k_value'][0],\n",
    "                    weights='distance' if config['distance_weighting'] else 'uniform',\n",
    "                    algorithm=config['neighbour_finding_algorithm'],\n",
    "                    p=config['p_value']\n",
    "                )\n",
    "\n",
    "            elif algorithm == 'extra_random_trees':\n",
    "                model = ExtraTreesRegressor(\n",
    "                    n_estimators=config['num_of_trees'][0],\n",
    "                    max_features=config['feature_sampling_statergy'],\n",
    "                    max_depth=config['max_depth'][0],\n",
    "                    min_samples_split=config['min_samples_per_leaf'][0],\n",
    "                    min_samples_leaf=config['min_samples_per_leaf'][1],\n",
    "                    n_jobs=config['parallelism']\n",
    "                )\n",
    "\n",
    "            elif algorithm == 'neural_network':\n",
    "                model = MLPRegressor(\n",
    "                    hidden_layer_sizes=config['hidden_layer_sizes'],\n",
    "                    activation=config['activation'],\n",
    "                    alpha=config['alpha_value'][0],\n",
    "                    max_iter=config['max_iterations'],\n",
    "                    tol=config['convergence_tolerance'],\n",
    "                    solver=config['solver'],\n",
    "                    learning_rate_init=config['initial_learning_rate'],\n",
    "                    batch_size='auto' if config['automatic_batching'] else 'None'\n",
    "                )\n",
    "    parameters = { #Add the custom parameters for the given model\n",
    "        \n",
    "    }\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=parameters, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(dataset.drop(target_column, axis=1), dataset[target_column])\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    model_results.append({\n",
    "                'model_name': model_name,\n",
    "                'best_model': best_model,\n",
    "                'best_params': best_params,\n",
    "                'best_score': best_score\n",
    "            })\n",
    "    \n",
    "    for result in model_results:\n",
    "        model_name = result['model_name']\n",
    "        best_model = result['best_model']\n",
    "        best_params = result['best_params']\n",
    "        best_score = result['best_score']\n",
    "\n",
    "        print(f\"Running {model_name} with best parameters: {best_params}\")\n",
    "        best_model.fit(X_train, Y_train)\n",
    "        predictions = best_model.predict(X_test, axis=1)\n",
    "        mse = mean_squared_error(Y_test, predictions)\n",
    "        print(f\"Mean Squared Error for {model_name}: {mse}\")\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d387cd8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c063c636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bd8232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
